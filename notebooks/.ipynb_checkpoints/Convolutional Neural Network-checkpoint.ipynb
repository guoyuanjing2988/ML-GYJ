{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When it comes to Convolutional Neural Network (CNN), the following picture always comes to the mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td> <img src=\"img/CNNArchitecture.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "All the squares and lines look fancy, but what does they really do and why people align the models in this way? We will go through all these questions today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Convolutional Neural Network (CNN) is a type of artificial neural network in which the connectivity pattern between its neurons is inspired by the organization of the animal visual cortex. In short, the model is trying to simulate the way animals see the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Components of Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As the graph above shows, there are two main parts of CNN: feature extraction part and classification part. The input of feature extraction section can n-dimensional, the output of the section is a 1-dimension vector, which can later be used as the feature is logistic regression and some other models to get the final result."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In feature extraction part, there are five main types of layers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Convolution Layer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Convolution layer is the core of CNN. It uses sliding windows across the whole matrix, and generate several feature maps. The following example will be more clear: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td> <img src=\"img/Convolution_schematic.gif\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The yellow 3*3 matrix is called a sliding window. It goes across the whole matrix and do dot product and each point. The right hand side is the new matrix generated. Sliding windows can be more than one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Activation Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Layer is a supplement of Convolution Layer. It defines the activation function for the sliding window. For example if the final prediction is wrong with current weights, we need to adjust the model so that it can give the correct result. The activation function is used to guide how to adjust the weights.\n",
    "Commonly used are two activation functions. First one is called sigmoid function. It is defined as <img src=\"img/sigmoid.svg\" alt=\"Drawing\" style=\"width: 100px;\"/> \n",
    "It looks like <img src=\"img/Logistic-curve.svg.png\" alt=\"Drawing\" style=\"width: 300px;\"/> \n",
    "The advantage of sigmoid function is that it returns a value between 0-1, which is good for classification. \n",
    "The second one is called Relu. It is defined as <img src=\"img/relu.svg\" alt=\"Drawing\" style=\"width: 150px;\"/> \n",
    "It looks like <img src=\"img/relu.jpeg\" alt=\"Drawing\" style=\"width: 300px;\"/> \n",
    "This is a much simpler function. Although it may return a value more than 1, it is experimentally proved as a better choice in most cases. And the time complexity is lower than sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)Sub-sampling Layer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sub-sampling Layer is used to reduce matrix size to speed up the process. Usually we use max-pooling, which takes in 4 adjacent cells and output the biggest one. The following sample shows the process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td> <img src=\"img/cnnmaxpooling.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In each colour there are four elements, the output is the biggest number. In this way a 4*4 matrix is reduced to 2*2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Flatten Layer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Flatten layer is used to make all the n-dimensional matrixs into a one-dimension vector as output. It basically just combine all the elements one by one and form a final vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Dropout Layer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dropout Layer is used to deal with overfitting situations. Usually a complex model often leads to overfitting, and dropout layer deals with it by randomly drop out a certain percentage of cells in the vector. For example, if the dropout ratio is 0.2, then 20% of the cells in the final vector is useless. In this way overfitting can be prevented."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "After feature extraction, the others are like what is covered in the last class. We just need to input the vector into a simple model and train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implementation of CNN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Convolutional Neural Network is not covered in scikit learn. However another python library keras has all the layers for CNN. All we need to do is to assemble in a proper way."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Convolution2D,Dropout,MaxPooling2D,Flatten,Dense\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Convolution2D(32, 3, 3, input_shape=(1, 28, 28), activation='relu'))\n",
    "cnn_model.add(Convolution2D(32,3,3,activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Dropout(0.25))\n",
    "cnn_model.add(Convolution2D(64,3,3, activation='relu'))\n",
    "cnn_model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Dropout(0.25))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(10, activation='softmax'))\n",
    "cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer=LogisticRegression(),metrics=['accuracy'])\n",
    "cnn_model.fit(input,outp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above is a example of a cnn model. It consists of four convolution layers, two maxpooling layers, two dropout layers and one flatten layer. In the end the output is a 10-element vector, corresponding to the digit recognition 0-9. Actually this model is proven to perform very well in digit recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Why use CNN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CNN was raised more than thirty years ago, but it is commonly used only in the recent five years. That's because of two disadvantages of CNN: Slow training speed and enormous requirement for training data. However, these two problems are solved by super computers. Then the advantage of CNN dominates other machine learning models."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First advantage is accuracy. That's because there are thousands, even millions of intermediate matrixs in the model. They can somehow captures significant features in the picture where even human eyes can't. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Second advantage is location resilience. It means that no matter where is the object in the picture, CNN can always find out. That is because of the convolution layer uses sliding windows across the picture so that every corner of the picture is scaned for the object. That is something that normal models can never achieve."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Set digit recognition as an example. The best error rate for normal models is around 3%, and using CNN can achieve an error rate of 0.7%, which is a significant improvement. CNN can also apply to real situations like identify road signs, while normal models can't."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CNN is the most state of art tool for image recognition. It is worth studying."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
